# 0.2.2

  The version 0.2.2 is a bugfix release for the 0.2 branch.
  
  ## Changes summary
  
  * Fix lexing of a whole expression input (using ctpl_lexer_expr_lex() or
    one of its variants);
  * Fix priority of boolean operators AND and OR;
  * Fix support of operators <= and >=;
  * Better error reporting in the expression lexer;
  * New alternative build system: Waf (from a work by Enrico Tr√∂ger, thanks).


# 0.2.1

  The version 0.2.1 is a bugfix release for the 0.2 branch.
  
  ## Changes summary
  
  * Do not export the private API;
  * Little cleaning of the build system.


# 0.2
  
  The version 0.2 is an API and ABI break from the previous 0.1 branch.
  
  ## Changes summary (in-depth):
  
  ### New features and important changes
  
  * GIO replaces LibMB. Impact is:
    * Less memory usage (input template may or may not be loaded into memory);
    * Small performance regression, between 8% to 19% [1] (on extreme cases),
      measured on heavy templates;
    * Any GIO stream may be live-lexed, from local files to remote FTP, Samba,
      DAV, etc.
  * Better lexer error reporting, with line and position marks;
  * Improved numeric constants loading, including:
    * Integers are now loaded as integers, impacting:
      * No more precision loss;
      * Shorter maximum value, but still more than reasonable (C's long: in 64
        bits machines should be something like from -9223372036854775807 to
        +9223372036854775807, and -2147483647 to +2147483647 on 32 bits
        machines).
    * Support for octal and binary constants via 0o and 0b prefix respectively;
  * Improved token representation, saving about from 19% to 28% of memory use
    for the token tree (no measurable performance impact) (already in 0.1.90);
  * Add support for single-line comments in environ descriptions;
  * Fix support of array values that starts with blanks in environ descriptions;
  * `make distcheck` and out-of-tree build now work;
  * Add man page for the ctpl command-line utility.
  
  As you can see, the main improvements of this release are less memory
  consumption (about 30/40% better!) and GIO usage bringing almost universal
  input.
  
  ## Quid of the performances?
  
  Yes, we lost about 8% to 19% [1] of speed. But I decided that the gain worth
  it: GIO allows live streams to be parsed without loading them previously into
  memory, which means that the memory usage is about the same minus about the
  size of the input template.
  Since the parsing of a 140M (28366227 lines) example template took 15.9612s
  before and 17.4756s now (8.67% slower), I thought it was reasonable when we
  gained about 140M of memory. Another test (135M input, 10944000 lines) took
  11.4204s before and 13.3378s now (14.38% slower), but needed about 130M less
  memory.
  
  And still note that these are very heavy templates (yes, 11-28.4M lines!), and
  real world templates are really really smaller. And this is the lexing, which
  is done only once per template, the parsing is not impacted.
  
  Finally, note that invalid templates may be found invalid without reading the
  whole input, especially if the invalid data is at the start. This makes for
  example a 350M invalid template to be immediately (huh, about 0.009s, and this
  includes program launching) reported as invalid, and this about 99% faster
  than before (without any I/O latency).
  
  [1] note that the measurement was done with all the changes (except token tree
      optimization), which can mean that the overhead is not only due to GIO but
      to the new features too.
      Another thing to note is that this measurement always used a cached file
      input, meaning that any I/O gain or loss due not to load the whole
      template at once was not took into account; but I/O doesn't make so much
      sense since it depends heavily on the input location (even two hard drives
      might behave quite differently, depending on their speed, cache size and
      so on). But with I/O, results moves from +18.66% to -3.59% slower.


# 0.1.90
  
  The version 0.1.90 is the last of the 0.1.x branch. It is the 0.2-minus-one
  release, with a part of the 0.1-compatible improvements that will come in the
  upcoming 0.2 branch.
  
  ## Changes summary
  
  * Improved token representation, saving about from 20% to 30% of memory use
    for the token tree (no measurable performance impact);
  * New ctpl_environ_foreach() and ctpl_environ_merge() functions;
  * Fix missing inclusion of readutils.h in the global header.


# 0.1.1
  
  The version 0.1.1 is a bugfix release for the 0.1 branch.
  
  ## Changes summary
  
  * Fixed stack overflow with very large token trees;
  * Great speed improvement with large token trees.


# 0.1
  
  The version 0.1 is the first release of CTPL. CTPL is a template engine
  library aiming to easily allow template parsing from C programs.
